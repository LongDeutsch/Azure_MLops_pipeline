{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import azureml.core\r\n",
        "# Check core SDK version number\r\n",
        "print(\"SDK version:\", azureml.core.VERSION)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "SDK version: 1.43.0\n"
        }
      ],
      "execution_count": 160,
      "metadata": {
        "gather": {
          "logged": 1666536285986
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\r\n",
        "df_loan = pd.read_csv('data/loan/Data_Loan.csv', index_col='Id')\r\n",
        "df_test = pd.read_csv('data/loan/Test Data.csv', index_col='ID')\r\n",
        "df_test_RF = pd.read_csv('data/loan/Sample Prediction Dataset.csv', index_col='ID')"
      ],
      "outputs": [],
      "execution_count": 161,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1666536286987
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_test = pd.concat([df_test,df_test_RF],axis=1)\r\n",
        "df_loan = pd.concat([df_loan, df_test], axis=0)"
      ],
      "outputs": [],
      "execution_count": 162,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1666536287172
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_loan.shape)\r\n",
        "df_loan.head()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "(280000, 12)\n"
        },
        {
          "output_type": "execute_result",
          "execution_count": 165,
          "data": {
            "text/plain": "    Income  Age  Experience Married/Single House_Ownership Car_Ownership  \\\n1  1303834   23           3         single          rented            no   \n2  7574516   40          10         single          rented            no   \n3  3991815   66           4        married          rented            no   \n4  6256451   41           2         single          rented           yes   \n5  5768871   47          11         single          rented            no   \n\n            Profession                 CITY           STATE  CURRENT_JOB_YRS  \\\n1  Mechanical_engineer                 Rewa  Madhya_Pradesh                3   \n2   Software_Developer             Parbhani     Maharashtra                9   \n3     Technical_writer            Alappuzha          Kerala                4   \n4   Software_Developer          Bhubaneswar          Odisha                2   \n5        Civil_servant  Tiruchirappalli[10]      Tamil_Nadu                3   \n\n   CURRENT_HOUSE_YRS  Risk_Flag  \n1                 13          0  \n2                 13          0  \n3                 10          0  \n4                 12          1  \n5                 14          1  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Income</th>\n      <th>Age</th>\n      <th>Experience</th>\n      <th>Married/Single</th>\n      <th>House_Ownership</th>\n      <th>Car_Ownership</th>\n      <th>Profession</th>\n      <th>CITY</th>\n      <th>STATE</th>\n      <th>CURRENT_JOB_YRS</th>\n      <th>CURRENT_HOUSE_YRS</th>\n      <th>Risk_Flag</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>1303834</td>\n      <td>23</td>\n      <td>3</td>\n      <td>single</td>\n      <td>rented</td>\n      <td>no</td>\n      <td>Mechanical_engineer</td>\n      <td>Rewa</td>\n      <td>Madhya_Pradesh</td>\n      <td>3</td>\n      <td>13</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>7574516</td>\n      <td>40</td>\n      <td>10</td>\n      <td>single</td>\n      <td>rented</td>\n      <td>no</td>\n      <td>Software_Developer</td>\n      <td>Parbhani</td>\n      <td>Maharashtra</td>\n      <td>9</td>\n      <td>13</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3991815</td>\n      <td>66</td>\n      <td>4</td>\n      <td>married</td>\n      <td>rented</td>\n      <td>no</td>\n      <td>Technical_writer</td>\n      <td>Alappuzha</td>\n      <td>Kerala</td>\n      <td>4</td>\n      <td>10</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>6256451</td>\n      <td>41</td>\n      <td>2</td>\n      <td>single</td>\n      <td>rented</td>\n      <td>yes</td>\n      <td>Software_Developer</td>\n      <td>Bhubaneswar</td>\n      <td>Odisha</td>\n      <td>2</td>\n      <td>12</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>5768871</td>\n      <td>47</td>\n      <td>11</td>\n      <td>single</td>\n      <td>rented</td>\n      <td>no</td>\n      <td>Civil_servant</td>\n      <td>Tiruchirappalli[10]</td>\n      <td>Tamil_Nadu</td>\n      <td>3</td>\n      <td>14</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 165,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1666536323685
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_loan.shape"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 113,
          "data": {
            "text/plain": "(252000, 12)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 113,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1666532657297
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Set up Compute"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.compute import ComputeTarget, AmlCompute\r\n",
        "from azureml.core.compute_target import ComputeTargetException\r\n",
        "from azureml.core import Workspace\r\n",
        "\r\n",
        "ws = Workspace.from_config()\r\n",
        "print(\"Workspace: \" + ws.name, \"Region: \" + ws.location, sep = '\\n')\r\n",
        "\r\n",
        "# Choose a name for your CPU cluster\r\n",
        "amlcompute_cluster_name = \"cpu-cluster\"\r\n",
        "\r\n",
        "# Verify that cluster does not exist already\r\n",
        "try:\r\n",
        "    aml_compute = ComputeTarget(workspace=ws, name=amlcompute_cluster_name)\r\n",
        "    print('Found existing cluster, use it.')\r\n",
        "except ComputeTargetException:\r\n",
        "    compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_DS12_V2',\r\n",
        "                                                           max_nodes=4)\r\n",
        "    aml_compute = ComputeTarget.create(ws, amlcompute_cluster_name, compute_config)\r\n",
        "\r\n",
        "aml_compute.wait_for_completion(show_output=True)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Workspace: mlopscourse\nRegion: eastus\nFound existing cluster, use it.\nSucceeded\nAmlCompute wait for completion finished\n\nMinimum number of nodes requested have been provisioned\n"
        }
      ],
      "execution_count": 114,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1666532659996
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Upload data to Azure Blob"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\r\n",
        "dataDir = \"data\"\r\n",
        "\r\n",
        "if not os.path.exists(dataDir):\r\n",
        "    os.mkdir(dataDir)\r\n",
        "\r\n",
        "loanDir = dataDir + \"/loan\"\r\n",
        "\r\n",
        "if not os.path.exists(loanDir):\r\n",
        "    os.mkdir(loanDir)\r\n",
        "    \r\n",
        "loanData = loanDir + \"/unprepared.parquet\"\r\n",
        "\r\n",
        "df_loan.to_csv(loanData, index=False)\r\n",
        "\r\n",
        "print(\"Data written to local folder.\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Data written to local folder.\n"
        }
      ],
      "execution_count": 115,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1666532661556
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\r\n",
        "# Default datastore\r\n",
        "default_store = ws.get_default_datastore() \r\n",
        "\r\n",
        "default_store.upload_files([loanData], \r\n",
        "                           target_path = 'loan', \r\n",
        "                           overwrite = True, \r\n",
        "                           show_progress = True)\r\n",
        "\r\n",
        "print(\"Upload calls completed.\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Uploading an estimated of 1 files\nUploading data/loan/unprepared.parquet\nUploaded data/loan/unprepared.parquet, 1 files out of an estimated total of 1\nUploaded 1 files\nUpload calls completed.\n"
        }
      ],
      "execution_count": 116,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1666532663987
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create and register datasets\r\n",
        "\r\n",
        "Bằng cách khởi tạo dataset, ta có thể tạo một liên kết đến địa chỉ data source. Nên khi ta áp dụng các kỹ thuật feature engineering lên bộ data, nó cũng sẽ được lưu giữ tại"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Dataset\r\n",
        "loan_data = Dataset.Tabular.from_delimited_files(default_store.path('loan/unprepared.parquet'))"
      ],
      "outputs": [],
      "execution_count": 117,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1666532671282
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loan_data = loan_data.register(ws, 'loan_data')"
      ],
      "outputs": [],
      "execution_count": 118,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1666532671988
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create run config"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.runconfig import RunConfiguration, DockerConfiguration\r\n",
        "from azureml.core.conda_dependencies import CondaDependencies\r\n",
        "\r\n",
        "# Create a new runconfig object\r\n",
        "aml_run_config = RunConfiguration()\r\n",
        "\r\n",
        "# Use the aml_compute being created above. \r\n",
        "aml_run_config.target = aml_compute\r\n",
        "\r\n",
        "# Enable Docker\r\n",
        "docker=DockerConfiguration(use_docker=True)\r\n",
        "aml_run_config.docker=docker\r\n",
        "\r\n",
        "# Use conda_dependencies.yml to create a conda environment in the Docker image for execution\r\n",
        "aml_run_config.environment.python.user_managed_dependencies = False\r\n",
        "\r\n",
        "# Specify CondaDependencies obj, add necessary packages\r\n",
        "aml_run_config.environment.python.conda_dependencies = CondaDependencies.create(\r\n",
        "    conda_packages=['pandas','scikit-learn'], \r\n",
        "    pip_packages=['azureml-sdk[automl]', 'pyarrow'])"
      ],
      "outputs": [],
      "execution_count": 119,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1666532672139
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature Engineering"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "miss = df_loan.isna().sum()\r\n",
        "miss = miss[miss>0]\r\n",
        "print(f\"Các dữ liệu thiếu:\\n{miss}\")\r\n",
        "print(f\"Số lượng cột có dữ liệu thiếu {len(miss)}\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Các dữ liệu thiếu:\nSeries([], dtype: int64)\nSố lượng cột có dữ liệu thiếu 0\n"
        }
      ],
      "execution_count": 120,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1666532672351
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "columns = ['Income','Age','Experience','Married/Single','House_Ownership',\t'Car_Ownership','Profession','CITY','STATE','CURRENT_JOB_YRS',\t'CURRENT_HOUSE_YRS','Risk_Flag']"
      ],
      "outputs": [],
      "execution_count": 121,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1666532672498
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Remove duplicate:\r\n",
        "Loại bỏ dữ liệu nhiễu bằng cách loại bỏ các dữ liệu trùng lặp ở các cột, ngoài trừ cột Risk_flag (khả năng vỡ nợ)"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "attributes=['Income','Age','Experience','Married/Single','House_Ownership',\r\n",
        "            'Car_Ownership','Profession','CITY','STATE','CURRENT_JOB_YRS',\r\n",
        "            'CURRENT_HOUSE_YRS' ]\r\n",
        "loan = df_loan.copy()\r\n",
        "df_loan = df_loan.drop_duplicates(subset=attributes)\r\n",
        "df_loan.shape\r\n",
        "\r\n",
        "print('Trước khi loại bỏ nhiễu:',loan.shape)\r\n",
        "loan = loan.drop_duplicates(subset=attributes)\r\n",
        "print('Sau khi loại bỏ nhiễu:', loan.shape)\r\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Trước khi loại bỏ nhiễu: (252000, 12)\nSau khi loại bỏ nhiễu: (42007, 12)\n"
        }
      ],
      "execution_count": 122,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1666532673014
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.pipeline.core import PipelineData\r\n",
        "from azureml.pipeline.steps import PythonScriptStep\r\n",
        "\r\n",
        "# python scripts folder\r\n",
        "prepare_data_folder = './prep_data'"
      ],
      "outputs": [],
      "execution_count": 123,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1666532673156
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define output after remove duplicate step\r\n",
        "clean_data = PipelineData(\"clean_data\", datastore=default_store).as_dataset()\r\n",
        "\r\n",
        "print('Remove noise script is in {}.'.format(os.path.realpath(prepare_data_folder)))\r\n",
        "\r\n",
        "# remove noise step creation\r\n",
        "# See the drop_noise.py for details about input and output\r\n",
        "cleanStep = PythonScriptStep(\r\n",
        "    name=\"drop druplicate Data\",\r\n",
        "    script_name=\"drop_noise.py\", \r\n",
        "    arguments=[\"--output_dropNoise\", clean_data],\r\n",
        "    inputs=[loan_data.as_named_input('raw_data')],\r\n",
        "    outputs=[clean_data],\r\n",
        "    compute_target=aml_compute,\r\n",
        "    runconfig=aml_run_config,\r\n",
        "    source_directory=prepare_data_folder,\r\n",
        "    allow_reuse=True\r\n",
        ")\r\n",
        "\r\n",
        "print(\"Remove noise data created.\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Remove noise script is in /mnt/batch/tasks/shared/LS_root/mounts/clusters/cpulong/code/Users/long.nguyen.1839/feat_engineering/prep_data.\nRemove noise data created.\n"
        }
      ],
      "execution_count": 124,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1666532673306
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Encode data:\r\n",
        " Chuyển đổi các label dạng string thành dạng numeric"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import preprocessing\r\n",
        "le = preprocessing.LabelEncoder()\r\n",
        "cols = ['Married/Single','House_Ownership','Car_Ownership','Profession','CITY','STATE']\r\n",
        "\r\n",
        "for i in cols:\r\n",
        "    loan[i]= le.fit_transform(loan[i])\r\n",
        "loan.head()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 125,
          "data": {
            "text/plain": "     Income  Age  Experience  Married/Single  House_Ownership  Car_Ownership  \\\nId                                                                             \n1   1303834   23           3               1                2              0   \n2   7574516   40          10               1                2              0   \n3   3991815   66           4               0                2              0   \n4   6256451   41           2               1                2              1   \n5   5768871   47          11               1                2              0   \n\n    Profession  CITY  STATE  CURRENT_JOB_YRS  CURRENT_HOUSE_YRS  Risk_Flag  \nId                                                                          \n1           33   251     13                3                 13          0  \n2           43   227     14                9                 13          0  \n3           47     8     12                4                 10          0  \n4           43    54     17                2                 12          1  \n5           11   296     22                3                 14          1  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Income</th>\n      <th>Age</th>\n      <th>Experience</th>\n      <th>Married/Single</th>\n      <th>House_Ownership</th>\n      <th>Car_Ownership</th>\n      <th>Profession</th>\n      <th>CITY</th>\n      <th>STATE</th>\n      <th>CURRENT_JOB_YRS</th>\n      <th>CURRENT_HOUSE_YRS</th>\n      <th>Risk_Flag</th>\n    </tr>\n    <tr>\n      <th>Id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>1303834</td>\n      <td>23</td>\n      <td>3</td>\n      <td>1</td>\n      <td>2</td>\n      <td>0</td>\n      <td>33</td>\n      <td>251</td>\n      <td>13</td>\n      <td>3</td>\n      <td>13</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>7574516</td>\n      <td>40</td>\n      <td>10</td>\n      <td>1</td>\n      <td>2</td>\n      <td>0</td>\n      <td>43</td>\n      <td>227</td>\n      <td>14</td>\n      <td>9</td>\n      <td>13</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3991815</td>\n      <td>66</td>\n      <td>4</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>47</td>\n      <td>8</td>\n      <td>12</td>\n      <td>4</td>\n      <td>10</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>6256451</td>\n      <td>41</td>\n      <td>2</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>43</td>\n      <td>54</td>\n      <td>17</td>\n      <td>2</td>\n      <td>12</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>5768871</td>\n      <td>47</td>\n      <td>11</td>\n      <td>1</td>\n      <td>2</td>\n      <td>0</td>\n      <td>11</td>\n      <td>296</td>\n      <td>22</td>\n      <td>3</td>\n      <td>14</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 125,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1666532673437
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define output after encoded step\r\n",
        "encoded_data = PipelineData(\"encoded_data\", datastore=default_store).as_dataset()\r\n",
        "\r\n",
        "print('Encode script is in {}.'.format(os.path.realpath(prepare_data_folder)))\r\n",
        "\r\n",
        "# encode step creation\r\n",
        "# See the encode.py for details about input and output\r\n",
        "encodeStep = PythonScriptStep(\r\n",
        "    name=\"Encode Loan Data\",\r\n",
        "    script_name=\"encode.py\", \r\n",
        "    arguments=[\"--output_encode\", encoded_data],\r\n",
        "    inputs=[clean_data.parse_parquet_files()],\r\n",
        "    outputs=[encoded_data],\r\n",
        "    compute_target=aml_compute,\r\n",
        "    runconfig=aml_run_config,\r\n",
        "    source_directory=prepare_data_folder,\r\n",
        "    allow_reuse=True\r\n",
        ")\r\n",
        "\r\n",
        "print(\"Encode data created.\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Encode script is in /mnt/batch/tasks/shared/LS_root/mounts/clusters/cpulong/code/Users/long.nguyen.1839/feat_engineering/prep_data.\nEncode data created.\n"
        }
      ],
      "execution_count": 126,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1666532673568
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Robust scaling"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loan.reset_index(drop=True, inplace=True)\r\n",
        "df_loan = loan"
      ],
      "outputs": [],
      "execution_count": 127,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1666532673815
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# robust scalling\r\n",
        "scaler = preprocessing.RobustScaler()\r\n",
        "loan = scaler.fit_transform(loan[attributes])\r\n",
        "loan = pd.DataFrame(loan, columns =attributes)"
      ],
      "outputs": [],
      "execution_count": 128,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1666532674233
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loan = pd.concat([loan,df_loan['Risk_Flag']], axis=1)\r\n",
        "loan.head()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 129,
          "data": {
            "text/plain": "     Income       Age  Experience  Married/Single  House_Ownership  \\\n0 -0.739674 -0.900000        -0.7             0.0              0.0   \n1  0.519909 -0.333333         0.0             0.0              0.0   \n2 -0.199743  0.533333        -0.6            -1.0              0.0   \n3  0.255152 -0.300000        -0.8             0.0              0.0   \n4  0.157212 -0.100000         0.1             0.0              0.0   \n\n   Car_Ownership  Profession      CITY     STATE  CURRENT_JOB_YRS  \\\n0            0.0    0.307692  0.588608 -0.058824        -0.500000   \n1            0.0    0.692308  0.436709  0.000000         0.500000   \n2            0.0    0.846154 -0.949367 -0.117647        -0.333333   \n3            1.0    0.692308 -0.658228  0.176471        -0.666667   \n4            0.0   -0.538462  0.873418  0.470588        -0.500000   \n\n   CURRENT_HOUSE_YRS  Risk_Flag  \n0                0.5          0  \n1                0.5          0  \n2               -1.0          0  \n3                0.0          1  \n4                1.0          1  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Income</th>\n      <th>Age</th>\n      <th>Experience</th>\n      <th>Married/Single</th>\n      <th>House_Ownership</th>\n      <th>Car_Ownership</th>\n      <th>Profession</th>\n      <th>CITY</th>\n      <th>STATE</th>\n      <th>CURRENT_JOB_YRS</th>\n      <th>CURRENT_HOUSE_YRS</th>\n      <th>Risk_Flag</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-0.739674</td>\n      <td>-0.900000</td>\n      <td>-0.7</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.307692</td>\n      <td>0.588608</td>\n      <td>-0.058824</td>\n      <td>-0.500000</td>\n      <td>0.5</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.519909</td>\n      <td>-0.333333</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.692308</td>\n      <td>0.436709</td>\n      <td>0.000000</td>\n      <td>0.500000</td>\n      <td>0.5</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-0.199743</td>\n      <td>0.533333</td>\n      <td>-0.6</td>\n      <td>-1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.846154</td>\n      <td>-0.949367</td>\n      <td>-0.117647</td>\n      <td>-0.333333</td>\n      <td>-1.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.255152</td>\n      <td>-0.300000</td>\n      <td>-0.8</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.692308</td>\n      <td>-0.658228</td>\n      <td>0.176471</td>\n      <td>-0.666667</td>\n      <td>0.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.157212</td>\n      <td>-0.100000</td>\n      <td>0.1</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>-0.538462</td>\n      <td>0.873418</td>\n      <td>0.470588</td>\n      <td>-0.500000</td>\n      <td>1.0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 129,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1666532674485
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loan.shape"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 130,
          "data": {
            "text/plain": "(42007, 12)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 130,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1666532674666
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define output after remove duplicate step\r\n",
        "scaled_data = PipelineData(\"scaled_data\", datastore=default_store).as_dataset()\r\n",
        "\r\n",
        "print('Scalling script is in {}.'.format(os.path.realpath(prepare_data_folder)))\r\n",
        "\r\n",
        "# Scalling step creation\r\n",
        "# See the scaling.py for details about input and output\r\n",
        "scalingStep = PythonScriptStep(\r\n",
        "    name=\"Robust scalling Data\",\r\n",
        "    script_name=\"scaling.py\", \r\n",
        "    arguments=[\"--output_scale\", scaled_data],\r\n",
        "    inputs=[encoded_data.parse_parquet_files()],\r\n",
        "    outputs=[scaled_data],\r\n",
        "    compute_target=aml_compute,\r\n",
        "    runconfig=aml_run_config,\r\n",
        "    source_directory=prepare_data_folder,\r\n",
        "    allow_reuse=True\r\n",
        ")\r\n",
        "\r\n",
        "print(\"scaled data created.\")\r\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Scalling script is in /mnt/batch/tasks/shared/LS_root/mounts/clusters/cpulong/code/Users/long.nguyen.1839/feat_engineering/prep_data.\nscaled data created.\n"
        }
      ],
      "execution_count": 131,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1666532674839
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train-test split"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_model_folder = './trainmodel'\r\n",
        "\r\n",
        "# train and test splits output\r\n",
        "output_split_train = PipelineData(\"output_split_train\", datastore=default_store).as_dataset()\r\n",
        "output_split_test = PipelineData(\"output_split_test\", datastore=default_store).as_dataset()\r\n",
        "\r\n",
        "print('Data spilt script is in {}.'.format(os.path.realpath(train_model_folder)))\r\n",
        "\r\n",
        "# test train split step creation\r\n",
        "# See the train_test_split.py for details about input and output\r\n",
        "testTrainSplitStep = PythonScriptStep(\r\n",
        "    name=\"Train Test Data Split\",\r\n",
        "    script_name=\"train_test_split.py\", \r\n",
        "    arguments=[\"--output_split_train\", output_split_train,\r\n",
        "               \"--output_split_test\", output_split_test],\r\n",
        "    inputs=[scaled_data.parse_parquet_files()],\r\n",
        "    outputs=[output_split_train, output_split_test],\r\n",
        "    compute_target=aml_compute,\r\n",
        "    runconfig = aml_run_config,\r\n",
        "    source_directory=train_model_folder,\r\n",
        "    allow_reuse=True\r\n",
        ")\r\n",
        "\r\n",
        "print(\"testTrainSplitStep created.\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Data spilt script is in /mnt/batch/tasks/shared/LS_root/mounts/clusters/cpulong/code/Users/long.nguyen.1839/feat_engineering/trainmodel.\ntestTrainSplitStep created.\n"
        }
      ],
      "execution_count": 132,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1666532675107
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Auto ML"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Experiment\r\n",
        "\r\n",
        "experiment = Experiment(ws, 'Fraud_detection_pipeline')\r\n",
        "\r\n",
        "print(\"Experiment created\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Experiment created\n"
        }
      ],
      "execution_count": 133,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1666532675374
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.train.automl import AutoMLConfig\r\n",
        "import json\r\n",
        "import logging\r\n",
        "\r\n",
        "# Change iterations to a reasonable number (50) to get better accuracy\r\n",
        "automl_settings = {\r\n",
        "    \"experiment_timeout_hours\": 0.3,\r\n",
        "    \"enable_early_stopping\": True,\r\n",
        "    \"iteration_timeout_minutes\": 5,\r\n",
        "    \"max_concurrent_iterations\": 4,\r\n",
        "    \"max_cores_per_iteration\": -1,\r\n",
        "    # \"n_cross_validations\": 2,\r\n",
        "    \"primary_metric\": \"AUC_weighted\",\r\n",
        "    \"featurization\": \"auto\",\r\n",
        "    \"verbosity\": logging.INFO,\r\n",
        "    \"enable_code_generation\": True,\r\n",
        "}\r\n",
        "training_dataset = output_split_train.parse_parquet_files().keep_columns(['Income','Age','Experience','Married/Single','House_Ownership',\r\n",
        "            'Car_Ownership','Profession','CITY','STATE','CURRENT_JOB_YRS',\r\n",
        "            'CURRENT_HOUSE_YRS','Risk_Flag'])\r\n",
        "\r\n",
        "automl_config = AutoMLConfig(\r\n",
        "    task=\"classification\",\r\n",
        "    debug_log=\"automl_errors.log\",\r\n",
        "    compute_target=aml_compute,\r\n",
        "    #experiment_exit_score=0.9984,\r\n",
        "    blocked_models=[\"KNN\", \"LinearSVM\"],\r\n",
        "    #enable_onnx_compatible_models=True,\r\n",
        "    training_data=training_dataset,\r\n",
        "    label_column_name='Risk_Flag',\r\n",
        "    # validation_data=validation_dataset,\r\n",
        "    **automl_settings,\r\n",
        ")\r\n",
        "                             \r\n",
        "print(\"AutoML config created.\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "AutoML config created.\n"
        }
      ],
      "execution_count": 134,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1666532676135
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.pipeline.steps import AutoMLStep\r\n",
        "\r\n",
        "trainWithAutomlStep = AutoMLStep(name='AutoML_Classification',\r\n",
        "                                 automl_config=automl_config,\r\n",
        "                                 allow_reuse=True)\r\n",
        "print(\"trainWithAutomlStep created.\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "trainWithAutomlStep created.\n"
        }
      ],
      "execution_count": 135,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1666532676293
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.pipeline.core import Pipeline\r\n",
        "from azureml.widgets import RunDetails\r\n",
        "\r\n",
        "pipeline_steps = [trainWithAutomlStep]\r\n",
        "\r\n",
        "pipeline = Pipeline(workspace = ws, steps=pipeline_steps)\r\n",
        "print(\"Pipeline is built.\")\r\n",
        "\r\n",
        "pipeline_run = experiment.submit(pipeline, regenerate_outputs=False)\r\n",
        "\r\n",
        "print(\"Pipeline submitted for execution.\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Pipeline is built.\nCreated step AutoML_Classification [d92a3a67][f080a17b-8cff-43fe-800f-3ee0747dd9cb], (This step will run and generate new outputs)Created step Train Test Data Split [240ce18a][5992be1d-816b-4bbb-88a4-e412f5226119], (This step will run and generate new outputs)\n\nCreated step Robust scalling Data [ce20a7f2][d81e1a68-5622-47b3-9b48-1262736bec13], (This step is eligible to reuse a previous run's output)\nCreated step Encode Loan Data [489c1994][b883c7c7-4515-46b8-91f7-a496cd03da6c], (This step is eligible to reuse a previous run's output)\nCreated step drop druplicate Data [b945d1e9][30636ead-3f13-462e-85b3-bc33a603cdf7], (This step is eligible to reuse a previous run's output)\nSubmitted PipelineRun 9b6e2fbc-45b7-4b1c-a138-5715c71db2b9\nLink to Azure Machine Learning Portal: https://ml.azure.com/runs/9b6e2fbc-45b7-4b1c-a138-5715c71db2b9?wsid=/subscriptions/bd28012e-c908-4162-ab7f-04c61a03a62a/resourcegroups/datascienceworld/workspaces/mlopscourse&tid=7bbbced8-b31a-4a36-95bb-9f06bc9d72a6\nPipeline submitted for execution.\n"
        }
      ],
      "execution_count": 136,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1666532683190
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "RunDetails(pipeline_run).show()"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "_PipelineWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO', …",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9881936c3ce745cbafc2de5d338c0759"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/aml.mini.widget.v1": "{\"status\": \"Completed\", \"workbench_run_details_uri\": \"https://ml.azure.com/runs/9b6e2fbc-45b7-4b1c-a138-5715c71db2b9?wsid=/subscriptions/bd28012e-c908-4162-ab7f-04c61a03a62a/resourcegroups/datascienceworld/workspaces/mlopscourse&tid=7bbbced8-b31a-4a36-95bb-9f06bc9d72a6\", \"run_id\": \"9b6e2fbc-45b7-4b1c-a138-5715c71db2b9\", \"run_properties\": {\"run_id\": \"9b6e2fbc-45b7-4b1c-a138-5715c71db2b9\", \"created_utc\": \"2022-10-23T13:44:53.018338Z\", \"properties\": {\"azureml.runsource\": \"azureml.PipelineRun\", \"runSource\": \"SDK\", \"runType\": \"SDK\", \"azureml.parameters\": \"{}\", \"azureml.continue_on_step_failure\": \"False\", \"azureml.continue_on_failed_optional_input\": \"True\", \"azureml.pipelineComponent\": \"pipelinerun\", \"stages\": \"{\\\"Initialization\\\":null,\\\"Execution\\\":{\\\"StartTime\\\":\\\"2022-10-23T13:44:54.5229754+00:00\\\",\\\"EndTime\\\":\\\"2022-10-23T14:10:16.9792928+00:00\\\",\\\"Status\\\":\\\"Finished\\\"}}\"}, \"tags\": {}, \"end_time_utc\": \"2022-10-23T14:10:17.059324Z\", \"status\": \"Completed\", \"log_files\": {\"logs/azureml/executionlogs.txt\": \"https://mlopscourse9423136648.blob.core.windows.net/azureml/ExperimentRun/dcid.9b6e2fbc-45b7-4b1c-a138-5715c71db2b9/logs/azureml/executionlogs.txt?sv=2019-07-07&sr=b&sig=vowna%2Ftw8sZr1JgZnev3Q%2FojA5XD6vWa2PCOIP7QrfQ%3D&skoid=68cf1fa8-5754-4fa7-8b3e-95ddf1955ee0&sktid=7bbbced8-b31a-4a36-95bb-9f06bc9d72a6&skt=2022-10-23T13%3A11%3A06Z&ske=2022-10-24T21%3A21%3A06Z&sks=b&skv=2019-07-07&st=2022-10-23T14%3A34%3A37Z&se=2022-10-23T22%3A44%3A37Z&sp=r\", \"logs/azureml/stderrlogs.txt\": \"https://mlopscourse9423136648.blob.core.windows.net/azureml/ExperimentRun/dcid.9b6e2fbc-45b7-4b1c-a138-5715c71db2b9/logs/azureml/stderrlogs.txt?sv=2019-07-07&sr=b&sig=QFzRnYrglQjtdqKIoaeyPvHUmDqfUq4JPo60rb8Uq4U%3D&skoid=68cf1fa8-5754-4fa7-8b3e-95ddf1955ee0&sktid=7bbbced8-b31a-4a36-95bb-9f06bc9d72a6&skt=2022-10-23T13%3A11%3A06Z&ske=2022-10-24T21%3A21%3A06Z&sks=b&skv=2019-07-07&st=2022-10-23T14%3A34%3A37Z&se=2022-10-23T22%3A44%3A37Z&sp=r\", \"logs/azureml/stdoutlogs.txt\": \"https://mlopscourse9423136648.blob.core.windows.net/azureml/ExperimentRun/dcid.9b6e2fbc-45b7-4b1c-a138-5715c71db2b9/logs/azureml/stdoutlogs.txt?sv=2019-07-07&sr=b&sig=3mZLpfujSRp5vKeR2qnPiJ8aci93tArTZ0JwL8afpGY%3D&skoid=68cf1fa8-5754-4fa7-8b3e-95ddf1955ee0&sktid=7bbbced8-b31a-4a36-95bb-9f06bc9d72a6&skt=2022-10-23T13%3A11%3A06Z&ske=2022-10-24T21%3A21%3A06Z&sks=b&skv=2019-07-07&st=2022-10-23T14%3A34%3A37Z&se=2022-10-23T22%3A44%3A37Z&sp=r\"}, \"log_groups\": [[\"logs/azureml/executionlogs.txt\", \"logs/azureml/stderrlogs.txt\", \"logs/azureml/stdoutlogs.txt\"]], \"run_duration\": \"0:25:24\", \"run_number\": \"1666532693\", \"run_queued_details\": {\"status\": \"Finished\", \"details\": null}}, \"child_runs\": [{\"run_id\": \"8d319507-489d-4308-81cd-a22325e85dd2\", \"name\": \"AutoML_Classification\", \"status\": \"Finished\", \"start_time\": \"2022-10-23T13:47:21.460831Z\", \"created_time\": \"2022-10-23T13:47:08.015881Z\", \"end_time\": \"2022-10-23T14:09:49.322806Z\", \"duration\": \"0:22:41\", \"run_number\": 1666532828, \"metric\": null, \"run_type\": \"azureml.StepRun\", \"training_percent\": null, \"created_time_dt\": \"2022-10-23T13:47:08.015881Z\", \"is_reused\": \"\"}, {\"run_id\": \"e355ee44-d27f-42f6-9b69-72804f100169\", \"name\": \"Train Test Data Split\", \"status\": \"Finished\", \"start_time\": \"2022-10-23T13:45:07.954344Z\", \"created_time\": \"2022-10-23T13:44:57.838165Z\", \"end_time\": \"2022-10-23T13:47:06.604828Z\", \"duration\": \"0:02:08\", \"run_number\": 1666532697, \"metric\": null, \"run_type\": \"azureml.StepRun\", \"training_percent\": null, \"created_time_dt\": \"2022-10-23T13:44:57.838165Z\", \"is_reused\": \"\"}, {\"run_id\": \"0256bfb4-e9fd-491c-ac7e-b761bd919b25\", \"name\": \"Robust scalling Data\", \"status\": \"Finished\", \"start_time\": \"2022-10-23T13:44:55.400169Z\", \"created_time\": \"2022-10-23T13:44:55.400169Z\", \"end_time\": \"2022-10-23T13:44:55.509141Z\", \"duration\": \"0:00:00\", \"run_number\": 1666532695, \"metric\": null, \"run_type\": \"azureml.StepRun\", \"training_percent\": null, \"created_time_dt\": \"2022-10-23T13:44:55.400169Z\", \"is_reused\": \"Yes\"}, {\"run_id\": \"b366c6da-798b-45b9-8e70-638c39f9de4d\", \"name\": \"Encode Loan Data\", \"status\": \"Finished\", \"start_time\": \"2022-10-23T13:44:55.011917Z\", \"created_time\": \"2022-10-23T13:44:55.011917Z\", \"end_time\": \"2022-10-23T13:44:55.085254Z\", \"duration\": \"0:00:00\", \"run_number\": 1666532695, \"metric\": null, \"run_type\": \"azureml.StepRun\", \"training_percent\": null, \"created_time_dt\": \"2022-10-23T13:44:55.011917Z\", \"is_reused\": \"Yes\"}, {\"run_id\": \"99f490c7-d93a-4aba-b750-5bc80c4e7024\", \"name\": \"drop druplicate Data\", \"status\": \"Finished\", \"start_time\": \"2022-10-23T13:44:54.671306Z\", \"created_time\": \"2022-10-23T13:44:54.671306Z\", \"end_time\": \"2022-10-23T13:44:54.741175Z\", \"duration\": \"0:00:00\", \"run_number\": 1666532694, \"metric\": null, \"run_type\": \"azureml.StepRun\", \"training_percent\": null, \"created_time_dt\": \"2022-10-23T13:44:54.671306Z\", \"is_reused\": \"Yes\"}], \"children_metrics\": {\"categories\": null, \"series\": null, \"metricName\": null}, \"run_metrics\": [], \"run_logs\": \"[2022-10-23 13:44:54Z] Completing processing run id 99f490c7-d93a-4aba-b750-5bc80c4e7024.\\n[2022-10-23 13:44:55Z] Completing processing run id b366c6da-798b-45b9-8e70-638c39f9de4d.\\n[2022-10-23 13:44:55Z] Completing processing run id 0256bfb4-e9fd-491c-ac7e-b761bd919b25.\\n[2022-10-23 13:44:56Z] Submitting 1 runs, first five are: 240ce18a:e355ee44-d27f-42f6-9b69-72804f100169\\n[2022-10-23 13:47:07Z] Completing processing run id e355ee44-d27f-42f6-9b69-72804f100169.\\n[2022-10-23 13:47:07Z] Submitting 1 runs, first five are: d92a3a67:8d319507-489d-4308-81cd-a22325e85dd2\\n[2022-10-23 14:10:16Z] Completing processing run id 8d319507-489d-4308-81cd-a22325e85dd2.\\n\\nRun is completed.\", \"graph\": {\"datasource_nodes\": {\"98bf33a3\": {\"node_id\": \"98bf33a3\", \"name\": \"loan_data\"}}, \"module_nodes\": {\"d92a3a67\": {\"node_id\": \"d92a3a67\", \"name\": \"AutoML_Classification\", \"status\": \"Finished\", \"_is_reused\": false, \"run_id\": \"8d319507-489d-4308-81cd-a22325e85dd2\"}, \"240ce18a\": {\"node_id\": \"240ce18a\", \"name\": \"Train Test Data Split\", \"status\": \"Finished\", \"_is_reused\": false, \"run_id\": \"e355ee44-d27f-42f6-9b69-72804f100169\"}, \"ce20a7f2\": {\"node_id\": \"ce20a7f2\", \"name\": \"Robust scalling Data\", \"status\": \"Finished\", \"_is_reused\": true, \"run_id\": \"0256bfb4-e9fd-491c-ac7e-b761bd919b25\"}, \"489c1994\": {\"node_id\": \"489c1994\", \"name\": \"Encode Loan Data\", \"status\": \"Finished\", \"_is_reused\": true, \"run_id\": \"b366c6da-798b-45b9-8e70-638c39f9de4d\"}, \"b945d1e9\": {\"node_id\": \"b945d1e9\", \"name\": \"drop druplicate Data\", \"status\": \"Finished\", \"_is_reused\": true, \"run_id\": \"99f490c7-d93a-4aba-b750-5bc80c4e7024\"}}, \"edges\": [{\"source_node_id\": \"240ce18a\", \"source_node_name\": \"Train Test Data Split\", \"source_name\": \"output_split_train\", \"target_name\": \"training_data\", \"dst_node_id\": \"d92a3a67\", \"dst_node_name\": \"AutoML_Classification\"}, {\"source_node_id\": \"ce20a7f2\", \"source_node_name\": \"Robust scalling Data\", \"source_name\": \"scaled_data\", \"target_name\": \"scaled_data\", \"dst_node_id\": \"240ce18a\", \"dst_node_name\": \"Train Test Data Split\"}, {\"source_node_id\": \"489c1994\", \"source_node_name\": \"Encode Loan Data\", \"source_name\": \"encoded_data\", \"target_name\": \"encoded_data\", \"dst_node_id\": \"ce20a7f2\", \"dst_node_name\": \"Robust scalling Data\"}, {\"source_node_id\": \"b945d1e9\", \"source_node_name\": \"drop druplicate Data\", \"source_name\": \"clean_data\", \"target_name\": \"clean_data\", \"dst_node_id\": \"489c1994\", \"dst_node_name\": \"Encode Loan Data\"}, {\"source_node_id\": \"98bf33a3\", \"source_node_name\": \"loan_data\", \"source_name\": \"data\", \"target_name\": \"raw_data\", \"dst_node_id\": \"b945d1e9\", \"dst_node_name\": \"drop druplicate Data\"}], \"child_runs\": [{\"run_id\": \"8d319507-489d-4308-81cd-a22325e85dd2\", \"name\": \"AutoML_Classification\", \"status\": \"Finished\", \"start_time\": \"2022-10-23T13:47:21.460831Z\", \"created_time\": \"2022-10-23T13:47:08.015881Z\", \"end_time\": \"2022-10-23T14:09:49.322806Z\", \"duration\": \"0:22:41\", \"run_number\": 1666532828, \"metric\": null, \"run_type\": \"azureml.StepRun\", \"training_percent\": null, \"created_time_dt\": \"2022-10-23T13:47:08.015881Z\", \"is_reused\": \"\"}, {\"run_id\": \"e355ee44-d27f-42f6-9b69-72804f100169\", \"name\": \"Train Test Data Split\", \"status\": \"Finished\", \"start_time\": \"2022-10-23T13:45:07.954344Z\", \"created_time\": \"2022-10-23T13:44:57.838165Z\", \"end_time\": \"2022-10-23T13:47:06.604828Z\", \"duration\": \"0:02:08\", \"run_number\": 1666532697, \"metric\": null, \"run_type\": \"azureml.StepRun\", \"training_percent\": null, \"created_time_dt\": \"2022-10-23T13:44:57.838165Z\", \"is_reused\": \"\"}, {\"run_id\": \"0256bfb4-e9fd-491c-ac7e-b761bd919b25\", \"name\": \"Robust scalling Data\", \"status\": \"Finished\", \"start_time\": \"2022-10-23T13:44:55.400169Z\", \"created_time\": \"2022-10-23T13:44:55.400169Z\", \"end_time\": \"2022-10-23T13:44:55.509141Z\", \"duration\": \"0:00:00\", \"run_number\": 1666532695, \"metric\": null, \"run_type\": \"azureml.StepRun\", \"training_percent\": null, \"created_time_dt\": \"2022-10-23T13:44:55.400169Z\", \"is_reused\": \"Yes\"}, {\"run_id\": \"b366c6da-798b-45b9-8e70-638c39f9de4d\", \"name\": \"Encode Loan Data\", \"status\": \"Finished\", \"start_time\": \"2022-10-23T13:44:55.011917Z\", \"created_time\": \"2022-10-23T13:44:55.011917Z\", \"end_time\": \"2022-10-23T13:44:55.085254Z\", \"duration\": \"0:00:00\", \"run_number\": 1666532695, \"metric\": null, \"run_type\": \"azureml.StepRun\", \"training_percent\": null, \"created_time_dt\": \"2022-10-23T13:44:55.011917Z\", \"is_reused\": \"Yes\"}, {\"run_id\": \"99f490c7-d93a-4aba-b750-5bc80c4e7024\", \"name\": \"drop druplicate Data\", \"status\": \"Finished\", \"start_time\": \"2022-10-23T13:44:54.671306Z\", \"created_time\": \"2022-10-23T13:44:54.671306Z\", \"end_time\": \"2022-10-23T13:44:54.741175Z\", \"duration\": \"0:00:00\", \"run_number\": 1666532694, \"metric\": null, \"run_type\": \"azureml.StepRun\", \"training_percent\": null, \"created_time_dt\": \"2022-10-23T13:44:54.671306Z\", \"is_reused\": \"Yes\"}]}, \"widget_settings\": {\"childWidgetDisplay\": \"popup\", \"send_telemetry\": false, \"log_level\": \"INFO\", \"sdk_version\": \"1.43.0\"}, \"loading\": false}"
          },
          "metadata": {}
        }
      ],
      "execution_count": 137,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1666534715599
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Explore results"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Before we proceed we need to wait for the run to complete.\r\n",
        "pipeline_run.wait_for_completion(show_output=False)\r\n",
        "\r\n",
        "# functions to download output to local and fetch as dataframe\r\n",
        "def get_download_path(download_path, output_name):\r\n",
        "    output_folder = os.listdir(download_path + '/azureml')[0]\r\n",
        "    path =  download_path + '/azureml/' + output_folder + '/' + output_name\r\n",
        "    return path\r\n",
        "\r\n",
        "def fetch_df(current_step, output_name):\r\n",
        "    output_data = current_step.get_output_data(output_name)    \r\n",
        "    download_path = './outputs/' + output_name\r\n",
        "    output_data.download(download_path, overwrite=True)\r\n",
        "    df_path = get_download_path(download_path, output_name) + '/processed.parquet'\r\n",
        "    return pd.read_parquet(df_path)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "PipelineRunId: 9b6e2fbc-45b7-4b1c-a138-5715c71db2b9\nLink to Azure Machine Learning Portal: https://ml.azure.com/runs/9b6e2fbc-45b7-4b1c-a138-5715c71db2b9?wsid=/subscriptions/bd28012e-c908-4162-ab7f-04c61a03a62a/resourcegroups/datascienceworld/workspaces/mlopscourse&tid=7bbbced8-b31a-4a36-95bb-9f06bc9d72a6\n"
        }
      ],
      "execution_count": 138,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1666534719026
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cleanse_step = pipeline_run.find_step_run(cleanStep.name)[0]\r\n",
        "\r\n",
        "cleansed_df = fetch_df(cleanse_step, clean_data.name)\r\n",
        "\r\n",
        "print(cleansed_df.shape)\r\n",
        "display(cleansed_df.head(5))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "(42007, 12)\n"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "    Income  Age  Experience Married/Single House_Ownership Car_Ownership  \\\n0  1303834   23           3         single          rented            no   \n1  7574516   40          10         single          rented            no   \n2  3991815   66           4        married          rented            no   \n3  6256451   41           2         single          rented           yes   \n4  5768871   47          11         single          rented            no   \n\n            Profession                 CITY           STATE  CURRENT_JOB_YRS  \\\n0  Mechanical_engineer                 Rewa  Madhya_Pradesh                3   \n1   Software_Developer             Parbhani     Maharashtra                9   \n2     Technical_writer            Alappuzha          Kerala                4   \n3   Software_Developer          Bhubaneswar          Odisha                2   \n4        Civil_servant  Tiruchirappalli[10]      Tamil_Nadu                3   \n\n   CURRENT_HOUSE_YRS  Risk_Flag  \n0                 13          0  \n1                 13          0  \n2                 10          0  \n3                 12          1  \n4                 14          1  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Income</th>\n      <th>Age</th>\n      <th>Experience</th>\n      <th>Married/Single</th>\n      <th>House_Ownership</th>\n      <th>Car_Ownership</th>\n      <th>Profession</th>\n      <th>CITY</th>\n      <th>STATE</th>\n      <th>CURRENT_JOB_YRS</th>\n      <th>CURRENT_HOUSE_YRS</th>\n      <th>Risk_Flag</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1303834</td>\n      <td>23</td>\n      <td>3</td>\n      <td>single</td>\n      <td>rented</td>\n      <td>no</td>\n      <td>Mechanical_engineer</td>\n      <td>Rewa</td>\n      <td>Madhya_Pradesh</td>\n      <td>3</td>\n      <td>13</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>7574516</td>\n      <td>40</td>\n      <td>10</td>\n      <td>single</td>\n      <td>rented</td>\n      <td>no</td>\n      <td>Software_Developer</td>\n      <td>Parbhani</td>\n      <td>Maharashtra</td>\n      <td>9</td>\n      <td>13</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3991815</td>\n      <td>66</td>\n      <td>4</td>\n      <td>married</td>\n      <td>rented</td>\n      <td>no</td>\n      <td>Technical_writer</td>\n      <td>Alappuzha</td>\n      <td>Kerala</td>\n      <td>4</td>\n      <td>10</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>6256451</td>\n      <td>41</td>\n      <td>2</td>\n      <td>single</td>\n      <td>rented</td>\n      <td>yes</td>\n      <td>Software_Developer</td>\n      <td>Bhubaneswar</td>\n      <td>Odisha</td>\n      <td>2</td>\n      <td>12</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5768871</td>\n      <td>47</td>\n      <td>11</td>\n      <td>single</td>\n      <td>rented</td>\n      <td>no</td>\n      <td>Civil_servant</td>\n      <td>Tiruchirappalli[10]</td>\n      <td>Tamil_Nadu</td>\n      <td>3</td>\n      <td>14</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 142,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1666534913039
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "encode_step = pipeline_run.find_step_run(encodeStep.name)[0]\r\n",
        "\r\n",
        "encoded_df = fetch_df(encode_step, encoded_data.name)\r\n",
        "\r\n",
        "print(encoded_df.shape)\r\n",
        "display(encoded_df.head(5))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "(42007, 13)\n"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "    Income  Age  Experience  Married/Single  House_Ownership  Car_Ownership  \\\n0  1303834   23           3               1                2              0   \n1  7574516   40          10               1                2              0   \n2  3991815   66           4               0                2              0   \n3  6256451   41           2               1                2              1   \n4  5768871   47          11               1                2              0   \n\n   Profession  CITY  STATE  CURRENT_JOB_YRS  CURRENT_HOUSE_YRS  Risk_Flag  \\\n0          33   251     13                3                 13          0   \n1          43   227     14                9                 13          0   \n2          47     8     12                4                 10          0   \n3          43    54     17                2                 12          1   \n4          11   296     22                3                 14          1   \n\n   __index_level_0__  \n0                  0  \n1                  1  \n2                  2  \n3                  3  \n4                  4  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Income</th>\n      <th>Age</th>\n      <th>Experience</th>\n      <th>Married/Single</th>\n      <th>House_Ownership</th>\n      <th>Car_Ownership</th>\n      <th>Profession</th>\n      <th>CITY</th>\n      <th>STATE</th>\n      <th>CURRENT_JOB_YRS</th>\n      <th>CURRENT_HOUSE_YRS</th>\n      <th>Risk_Flag</th>\n      <th>__index_level_0__</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1303834</td>\n      <td>23</td>\n      <td>3</td>\n      <td>1</td>\n      <td>2</td>\n      <td>0</td>\n      <td>33</td>\n      <td>251</td>\n      <td>13</td>\n      <td>3</td>\n      <td>13</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>7574516</td>\n      <td>40</td>\n      <td>10</td>\n      <td>1</td>\n      <td>2</td>\n      <td>0</td>\n      <td>43</td>\n      <td>227</td>\n      <td>14</td>\n      <td>9</td>\n      <td>13</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3991815</td>\n      <td>66</td>\n      <td>4</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>47</td>\n      <td>8</td>\n      <td>12</td>\n      <td>4</td>\n      <td>10</td>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>6256451</td>\n      <td>41</td>\n      <td>2</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>43</td>\n      <td>54</td>\n      <td>17</td>\n      <td>2</td>\n      <td>12</td>\n      <td>1</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5768871</td>\n      <td>47</td>\n      <td>11</td>\n      <td>1</td>\n      <td>2</td>\n      <td>0</td>\n      <td>11</td>\n      <td>296</td>\n      <td>22</td>\n      <td>3</td>\n      <td>14</td>\n      <td>1</td>\n      <td>4</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 143,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1666535028077
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scale_step = pipeline_run.find_step_run(scalingStep.name)[0]\r\n",
        "\r\n",
        "scaled_df = fetch_df(scale_step, scaled_data.name)\r\n",
        "\r\n",
        "print(scaled_df.shape)\r\n",
        "display(scaled_df.head(5))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "(42007, 12)\n"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "     Income       Age  Experience  Married/Single  House_Ownership  \\\n0 -0.739674 -0.900000        -0.7             0.0              0.0   \n1  0.519909 -0.333333         0.0             0.0              0.0   \n2 -0.199743  0.533333        -0.6            -1.0              0.0   \n3  0.255152 -0.300000        -0.8             0.0              0.0   \n4  0.157212 -0.100000         0.1             0.0              0.0   \n\n   Car_Ownership  Profession      CITY     STATE  CURRENT_JOB_YRS  \\\n0            0.0    0.307692  0.588608 -0.058824        -0.500000   \n1            0.0    0.692308  0.436709  0.000000         0.500000   \n2            0.0    0.846154 -0.949367 -0.117647        -0.333333   \n3            1.0    0.692308 -0.658228  0.176471        -0.666667   \n4            0.0   -0.538462  0.873418  0.470588        -0.500000   \n\n   CURRENT_HOUSE_YRS  Risk_Flag  \n0                0.5          0  \n1                0.5          0  \n2               -1.0          0  \n3                0.0          1  \n4                1.0          1  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Income</th>\n      <th>Age</th>\n      <th>Experience</th>\n      <th>Married/Single</th>\n      <th>House_Ownership</th>\n      <th>Car_Ownership</th>\n      <th>Profession</th>\n      <th>CITY</th>\n      <th>STATE</th>\n      <th>CURRENT_JOB_YRS</th>\n      <th>CURRENT_HOUSE_YRS</th>\n      <th>Risk_Flag</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-0.739674</td>\n      <td>-0.900000</td>\n      <td>-0.7</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.307692</td>\n      <td>0.588608</td>\n      <td>-0.058824</td>\n      <td>-0.500000</td>\n      <td>0.5</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.519909</td>\n      <td>-0.333333</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.692308</td>\n      <td>0.436709</td>\n      <td>0.000000</td>\n      <td>0.500000</td>\n      <td>0.5</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-0.199743</td>\n      <td>0.533333</td>\n      <td>-0.6</td>\n      <td>-1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.846154</td>\n      <td>-0.949367</td>\n      <td>-0.117647</td>\n      <td>-0.333333</td>\n      <td>-1.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.255152</td>\n      <td>-0.300000</td>\n      <td>-0.8</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.692308</td>\n      <td>-0.658228</td>\n      <td>0.176471</td>\n      <td>-0.666667</td>\n      <td>0.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.157212</td>\n      <td>-0.100000</td>\n      <td>0.1</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>-0.538462</td>\n      <td>0.873418</td>\n      <td>0.470588</td>\n      <td>-0.500000</td>\n      <td>1.0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 144,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1666535134404
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\r\n",
        "split_step = pipeline_run.find_step_run(testTrainSplitStep.name)[0]\r\n",
        "\r\n",
        "train_df = fetch_df(split_step, output_split_train.name)\r\n",
        "\r\n",
        "print(train_df.shape)\r\n",
        "display(train_df.head(5))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "(33605, 12)\n"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "     Income       Age  Experience  Married/Single  House_Ownership  \\\n0 -0.257675 -0.033333        -0.3             0.0              0.0   \n1 -0.231296  0.933333         0.2            -1.0              0.0   \n2  0.715899 -0.266667         0.3             0.0              0.0   \n3  0.700409 -0.366667        -0.9             0.0              0.0   \n4  0.657288 -0.733333         0.3             0.0              0.0   \n\n   Car_Ownership  Profession      CITY     STATE  CURRENT_JOB_YRS  \\\n0            1.0    0.538462  0.101266  0.294118        -0.166667   \n1            1.0    0.653846  0.468354  0.000000        -0.333333   \n2            0.0   -0.230769 -0.069620  0.470588        -0.500000   \n3            0.0   -0.153846  0.354430 -0.529412        -0.833333   \n4            0.0   -0.923077 -0.436709  0.823529         0.166667   \n\n   CURRENT_HOUSE_YRS  Risk_Flag  \n0               -0.5          0  \n1                0.0          1  \n2                0.5          1  \n3                0.5          0  \n4               -0.5          0  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Income</th>\n      <th>Age</th>\n      <th>Experience</th>\n      <th>Married/Single</th>\n      <th>House_Ownership</th>\n      <th>Car_Ownership</th>\n      <th>Profession</th>\n      <th>CITY</th>\n      <th>STATE</th>\n      <th>CURRENT_JOB_YRS</th>\n      <th>CURRENT_HOUSE_YRS</th>\n      <th>Risk_Flag</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-0.257675</td>\n      <td>-0.033333</td>\n      <td>-0.3</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.538462</td>\n      <td>0.101266</td>\n      <td>0.294118</td>\n      <td>-0.166667</td>\n      <td>-0.5</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-0.231296</td>\n      <td>0.933333</td>\n      <td>0.2</td>\n      <td>-1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.653846</td>\n      <td>0.468354</td>\n      <td>0.000000</td>\n      <td>-0.333333</td>\n      <td>0.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.715899</td>\n      <td>-0.266667</td>\n      <td>0.3</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>-0.230769</td>\n      <td>-0.069620</td>\n      <td>0.470588</td>\n      <td>-0.500000</td>\n      <td>0.5</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.700409</td>\n      <td>-0.366667</td>\n      <td>-0.9</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>-0.153846</td>\n      <td>0.354430</td>\n      <td>-0.529412</td>\n      <td>-0.833333</td>\n      <td>0.5</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.657288</td>\n      <td>-0.733333</td>\n      <td>0.3</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>-0.923077</td>\n      <td>-0.436709</td>\n      <td>0.823529</td>\n      <td>0.166667</td>\n      <td>-0.5</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 146,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1666535237399
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "split_step = pipeline_run.find_step_run(testTrainSplitStep.name)[0]\r\n",
        "\r\n",
        "test_df = fetch_df(split_step, output_split_test.name)\r\n",
        "\r\n",
        "print(test_df.shape)\r\n",
        "display(test_df.head(5))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "(8402, 12)\n"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "     Income       Age  Experience  Married/Single  House_Ownership  \\\n0  0.034590 -0.966667        -0.8             0.0              0.0   \n1  0.783744  0.833333         0.4             0.0              0.0   \n2 -0.918826  0.000000         0.9             0.0              0.0   \n3  1.000799  0.400000         0.1             0.0              0.0   \n4 -0.147652 -0.733333         1.0             0.0              0.0   \n\n   Car_Ownership  Profession      CITY     STATE  CURRENT_JOB_YRS  \\\n0            0.0   -0.692308  0.683544  0.647059        -0.666667   \n1            0.0   -0.538462  0.006329 -0.705882        -0.333333   \n2            0.0    0.192308  0.044304  0.352941        -0.333333   \n3            1.0    0.269231 -0.943038  0.647059         0.000000   \n4            0.0   -0.730769 -0.886076  0.647059        -0.166667   \n\n   CURRENT_HOUSE_YRS  Risk_Flag  \n0                0.0          0  \n1               -0.5          0  \n2                1.0          0  \n3                1.0          0  \n4                1.0          0  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Income</th>\n      <th>Age</th>\n      <th>Experience</th>\n      <th>Married/Single</th>\n      <th>House_Ownership</th>\n      <th>Car_Ownership</th>\n      <th>Profession</th>\n      <th>CITY</th>\n      <th>STATE</th>\n      <th>CURRENT_JOB_YRS</th>\n      <th>CURRENT_HOUSE_YRS</th>\n      <th>Risk_Flag</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.034590</td>\n      <td>-0.966667</td>\n      <td>-0.8</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>-0.692308</td>\n      <td>0.683544</td>\n      <td>0.647059</td>\n      <td>-0.666667</td>\n      <td>0.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.783744</td>\n      <td>0.833333</td>\n      <td>0.4</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>-0.538462</td>\n      <td>0.006329</td>\n      <td>-0.705882</td>\n      <td>-0.333333</td>\n      <td>-0.5</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-0.918826</td>\n      <td>0.000000</td>\n      <td>0.9</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.192308</td>\n      <td>0.044304</td>\n      <td>0.352941</td>\n      <td>-0.333333</td>\n      <td>1.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.000799</td>\n      <td>0.400000</td>\n      <td>0.1</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.269231</td>\n      <td>-0.943038</td>\n      <td>0.647059</td>\n      <td>0.000000</td>\n      <td>1.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-0.147652</td>\n      <td>-0.733333</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>-0.730769</td>\n      <td>-0.886076</td>\n      <td>0.647059</td>\n      <td>-0.166667</td>\n      <td>1.0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 148,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1666535269509
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python38-azureml",
      "language": "python",
      "display_name": "Python 3.8 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernel_info": {
      "name": "python38-azureml"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}